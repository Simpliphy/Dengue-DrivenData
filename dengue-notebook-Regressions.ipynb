{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── benchmark_arima.csv\r\n",
      "├── benchmark.csv\r\n",
      "├── \u001b[01;34mbenchmarks-master\u001b[00m\r\n",
      "│   ├── bees-benchmark.ipynb\r\n",
      "│   ├── dengue-benchmark-statsmodels.ipynb\r\n",
      "│   ├── fogwater-benchmark-model.ipynb\r\n",
      "│   ├── LICENSE\r\n",
      "│   └── README.md\r\n",
      "├── \u001b[01;31mbenchmarks-master.zip\u001b[00m\r\n",
      "├── Dengue-benchmark-ARIMA.ipynb\r\n",
      "├── dengue_features_test.csv\r\n",
      "├── dengue_features_train.csv\r\n",
      "├── dengue_labels_train.csv\r\n",
      "├── dengue-notebook.ipynb\r\n",
      "├── dengue-notebook-Regressions.ipynb\r\n",
      "├── \u001b[01;35mIquitos-plaza.jpg\u001b[00m\r\n",
      "├── random_forest_regression.csv\r\n",
      "├── README.md\r\n",
      "├── results.csv\r\n",
      "├── results_lasso.csv\r\n",
      "├── results_RandomForestRegression.csv\r\n",
      "├── results_Ridge.csv\r\n",
      "├── San_Juan-Puerto_Rico.JPG\r\n",
      "└── submission_format.csv\r\n",
      "\r\n",
      "1 directory, 23 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the provided data\n",
    "train_features = pd.read_csv('dengue_features_train.csv')\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'year', 'weekofyear', 'week_start_date', 'ndvi_ne', 'ndvi_nw',\n",
       "       'ndvi_se', 'ndvi_sw', 'precipitation_amt_mm', 'reanalysis_air_temp_k',\n",
       "       'reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k',\n",
       "       'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k',\n",
       "       'reanalysis_precip_amt_kg_per_m2',\n",
       "       'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm',\n",
       "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
       "       'station_avg_temp_c', 'station_diur_temp_rng_c', 'station_max_temp_c',\n",
       "       'station_min_temp_c', 'station_precip_mm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_lag(dataframe, columns,number_of_lag):\n",
    "    \n",
    "    for column in columns: # for each feature (column)\n",
    "        for lag in range(number_of_lag): # for each time step (lag)\n",
    "            dataframe[column + \"_time - \"+ str(lag)] = dataframe[column].shift(lag) # copy the previous value\n",
    "            \n",
    "    #remove the first number_of_lag rows\n",
    "    dataframe.fillna(method='backfill', inplace=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def preprocess_data(data_path, labels_path=None):\n",
    "    lag_step = 20\n",
    "    \n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "    \n",
    "    # select features we want\n",
    "    features =['ndvi_ne', 'ndvi_nw',\n",
    "       'ndvi_se', 'ndvi_sw', 'precipitation_amt_mm', \n",
    "       'reanalysis_avg_temp_k',\n",
    "       'reanalysis_precip_amt_kg_per_m2',\n",
    "       'reanalysis_relative_humidity_percent',\n",
    "       'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k', 'station_precip_mm']\n",
    "    \n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sj = df.loc['sj']\n",
    "    iq = df.loc['iq']\n",
    "    \n",
    "    #add lag\n",
    "    sj = add_lag(sj, features, lag_step)\n",
    "    iq = add_lag(iq, features, lag_step)\n",
    "    \n",
    "    # fill navalues\n",
    "    sj.fillna(method='backfill', inplace=True)\n",
    "    iq.fillna(method='backfill', inplace=True)\n",
    "    \n",
    "    return sj, iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/louis/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sj_train, iq_train = preprocess_data('dengue_features_train.csv',\n",
    "                                    labels_path=\"dengue_labels_train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "#>>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "#>>> y = np.array([1, 2, 3, 4])\n",
    "#>>> tscv = TimeSeriesSplit(n_splits=3)\n",
    "#>>> print(tscv)  \n",
    "#TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
    "#>>> for train_index, test_index in tscv.split(X):\n",
    "#...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#...    X_train, X_test = X[train_index], X[test_index]\n",
    "#...    y_train, y_test = y[train_index], y[test_index]\n",
    "#TRAIN: [0] TEST: [1]\n",
    "#TRAIN: [0 1] TEST: [2]\n",
    "#TRAIN: [0 1 2] TEST: [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sj_features  = sj_train.drop('total_cases', axis =1)\n",
    "sj_targets = sj_train['total_cases']\n",
    "\n",
    "iq_features  = iq_train.drop('total_cases', axis =1)\n",
    "iq_targets = iq_train['total_cases']\n",
    "\n",
    "def split_time_series(X, y, test_set_ratio):\n",
    "    \n",
    "\n",
    "    number_of_examples = X.shape[0]\n",
    "    last_index_in_train_set = floor( (1-test_set_ratio)*number_of_examples )\n",
    "    \n",
    "    X_train = X[:last_index_in_train_set]\n",
    "    X_test = X[last_index_in_train_set:]\n",
    "    \n",
    "    y_train = y[:last_index_in_train_set]\n",
    "    y_test = y[last_index_in_train_set:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "test_set_ratio = 0.3 \n",
    "\n",
    "X_sj_train, X_sj_test, y_sj_train, y_sj_test = split_time_series(sj_features, sj_targets, test_set_ratio)\n",
    "X_iq_train, X_iq_test, y_iq_train, y_iq_test = split_time_series(iq_features, iq_targets, test_set_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# for San Juan\n",
    "def find_best_params(X_train,y_train,X_val,y_val,n_estimators,max_depths):\n",
    "    \n",
    "    print(\"mean_absolute_error [n_estomators,max_depth]: mae\")\n",
    "    scores_mean_absolute_error = np.zeros((len(n_estimators), len(max_depths) ))\n",
    "    best_score_mean_absolute_error = float(\"inf\")\n",
    "    best_parameters = [0,0]\n",
    "    \n",
    "    for i  in range(len(n_estimators)):\n",
    "        for j in range(len(max_depths)):\n",
    "\n",
    "            n_estimator = n_estimators[i]\n",
    "            max_depth = max_depths[j]\n",
    "\n",
    "            regressor_RF = RandomForestRegressor(n_estimators=n_estimator,max_depth = max_depth, random_state=0, n_jobs=8)\n",
    "            regressor_RF.fit(X_train,y_train)\n",
    "            predictions = regressor_RF.predict(X_val)\n",
    "\n",
    "            mean_absolute_error_ = mean_absolute_error(y_val, predictions)\n",
    "            print(\"mean_absolute_error [{0},{1}]: {2}\".format(n_estimator,max_depth,mean_absolute_error_))\n",
    "            scores_mean_absolute_error[i,j] = mean_absolute_error_\n",
    "\n",
    "            if mean_absolute_error_ < best_score_mean_absolute_error:\n",
    "               best_score_mean_absolute_error = mean_absolute_error_\n",
    "               best_parameters = [n_estimator, max_depth] \n",
    "    \n",
    "        \n",
    "\n",
    "    print(\"\\n-------------------------\")\n",
    "    print(\"best_mean_absolute_error: {0}\".format(best_score_mean_absolute_error))         \n",
    "    print(\"n_estimators: {0}\".format(best_parameters[0]))         \n",
    "    print(\"max_depth: {0}\".format(best_parameters[1])) \n",
    "    print(\"-------------------------\\n\")\n",
    "    \n",
    "    best_n_estimators = best_parameters[0]\n",
    "    best_max_depth = best_parameters[1]\n",
    "    \n",
    "    return best_n_estimators, best_max_depth,scores_mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error [n_estomators,max_depth]: mae\n",
      "mean_absolute_error [20,15]: 29.845397749158924\n",
      "mean_absolute_error [20,20]: 30.089825434478982\n",
      "mean_absolute_error [20,40]: 30.319572953736653\n",
      "mean_absolute_error [100,15]: 31.274181070022884\n",
      "mean_absolute_error [100,20]: 31.11010967837402\n",
      "mean_absolute_error [100,40]: 31.12288256227758\n",
      "mean_absolute_error [400,15]: 30.972119275235553\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [20,100,400,800,1200]\n",
    "max_depths = [15,20, 40]\n",
    "\n",
    "n_estimators_sj, max_depth_sj, scores__mean_absulute_error_sj = find_best_params(X_sj_train,\n",
    "                                                                                 y_sj_train,\n",
    "                                                                                 X_sj_test,\n",
    "                                                                                 y_sj_test,\n",
    "                                                                                 n_estimators,\n",
    "                                                                                 max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores__mean_absulute_error_sj, interpolation='nearest', cmap=plt.cm.hot_r)\n",
    "plt.ylabel('n_estimators')\n",
    "plt.xlabel('max_depth')\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(len(n_estimators)), n_estimators, rotation=45)\n",
    "plt.xticks(np.arange(len(max_depths)), max_depths)\n",
    "plt.title('Validation accuracy for San Juan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators_iq, max_depth_iq, scores__mean_absulute_error_iq = find_best_params(X_iq_train,\n",
    "                                                                                 y_iq_train,\n",
    "                                                                                 X_iq_test,\n",
    "                                                                                 y_iq_test,\n",
    "                                                                                 n_estimators,\n",
    "                                                                                 max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores__mean_absulute_error_iq, interpolation='nearest', cmap=plt.cm.hot_r)\n",
    "plt.ylabel('n_estimators')\n",
    "plt.xlabel('max_depth')\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(len(n_estimators)), n_estimators, rotation=45)\n",
    "plt.xticks(np.arange(len(max_depths)), max_depths)\n",
    "plt.title('Validation accuracy for Iquitos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor_RF_sj = RandomForestRegressor(n_estimators = n_estimators_sj ,\n",
    "                                        max_depth=max_depth_sj,\n",
    "                                        random_state=101,\n",
    "                                        n_jobs=8)\n",
    "\n",
    "regressor_RF_iq = RandomForestRegressor(n_estimators=n_estimators_iq ,\n",
    "                                        max_depth=max_depth_iq,\n",
    "                                        random_state=101,\n",
    "                                        n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor_RF_sj.fit(X_sj_train,y_sj_train)\n",
    "regressor_RF_iq.fit(X_iq_train,y_iq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_sj = regressor_RF_sj.predict(X_sj_test)\n",
    "predictions_iq = regressor_RF_iq.predict(X_iq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"For San Juan\\n \")\n",
    "print(\"mean_squared_error: {0}\".format(mean_squared_error(y_sj_test, predictions_sj)))\n",
    "print(\"mean_absolute_error: {0}\".format(mean_absolute_error(y_sj_test, predictions_sj)))\n",
    "print(\"\\nFor Iquitos\\n \")\n",
    "print(\"mean_squared_error: {0}\".format(mean_squared_error(y_iq_test, predictions_iq)))\n",
    "print(\"mean_absolute_error: {0}\".format(mean_absolute_error(y_iq_test, predictions_iq)))\n",
    "\n",
    "df1 = pd.DataFrame({\"predicted\":predictions_sj,\"actual\":y_sj_test})\n",
    "\n",
    "df1.plot()\n",
    "plt.title('San Juan: predicted vs actual')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "df2 = pd.DataFrame({\"predicted\":predictions_iq,\"actual\":y_iq_test})\n",
    "\n",
    "df2.plot()\n",
    "plt.title('Iquitos: predicted vs actual')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor_RF_sj_final = RandomForestRegressor(n_estimators = n_estimators_sj ,\n",
    "                                        max_depth=max_depth_sj,\n",
    "                                        random_state=101,\n",
    "                                        n_jobs=8)\n",
    "\n",
    "regressor_RF_iq_final = RandomForestRegressor(n_estimators=n_estimators_iq ,\n",
    "                                        max_depth=max_depth_iq,\n",
    "                                        random_state=101,\n",
    "                                        n_jobs=8)\n",
    "\n",
    "regressor_RF_sj.fit(sj_features,sj_targets)\n",
    "regressor_RF_iq.fit(iq_features,iq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sj_test, iq_test = preprocess_data('dengue_features_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "sj_predictions = regressor_RF_sj.predict(sj_test).astype(int)\n",
    "iq_predictions = regressor_RF_iq.predict(iq_test).astype(int)\n",
    "\n",
    "submission = pd.read_csv(\"submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate((sj_predictions, iq_predictions),axis=0)\n",
    "submission.to_csv(\"random_forest_regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
